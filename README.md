# Fall 2020 CSCI 576 Multimedia Project
Instructor: [Parag Havaldar](https://www.linkedin.com/in/parag-havaldar-86467/)

[<img src="readme/viterbi_logo.png" width="200" height="50"/>](https://classes.usc.edu/term-20203/course/csci-576/) [<img src="readme/trello-mark-blue.png" width="50" height="50"/>](https://trello.com/b/FC2qwydh/project)

## Project description

Text based searching today has become a natural part of how we access information and there are many ways to search and rank textual information. For instance, you can search using a specific text string query while browsing a big text document and just as easily bring up other documents that contain the same query text string. Search engines like google, bing, yahoo etc. enable you to search the whole world wide web of textural web pages for specific strings and rank them in an order of importance using various classes of search algorithms.

Now with the advances in inexpensive digital video (and audio) capture devices, media data is commonplace now. There is a lot of digital video information everywhere – streamed to you via the internet and cable networks, hosted on websites and social media networks, your own personal hard disks etc. With a lot of video/audio/image information, there needs to be a search paradigm to make sense of it. However, the search paradigms and methodologies for media data are as well formed and are still related to text information and/or metadata that is annotated around the media data.

Rather than using text to query media, another natural paradigm might be to use media itself – for instance given short video clip, you want to search through an entire database of videos to find the video which contains the “same” query or “similar” content as in the query clip. The motivating question here is - what is involved in developing a system that takes a short video clip as input and very quickly produces a ranked list of videos (from a database) that either contains the queried short clip or contains similar queried short clips. This is no doubt a complex problem with many nuances to consider but is also a practical and useful problem that needs a solution.

This project aims to provide a decent solution to this hard problem.


## Datasets
We will be using these following datasets:

1. Data_jpg
2. Data_wav


## Team members
**[Haixiang Liu](https://www.linkedin.com/in/haixiang-liu-5793981b4/)** is a great student.

[<img src="readme/yaqi.jpg" width="200">](mailto:yaqishao@usc.edu)

**[Yaqi Shao](https://www.linkedin.com/in/yaqi-shao-2805761b9/)** is a Computer Science student at USC and also a student worker at the Signal and Image Processing department at EES.

[<img src="https://ca.slack-edge.com/ENCHN8KSS-W0182SSSPSB-2290b4b686dc-512" width="200"/>](mailto:juntaosh@usc.edu)

**[Juntao Shen](https://www.linkedin.com/in/juntao-kenneth-shen-b31b3094/)** is a second year graduate student in the Computer Science Data Science program. He obtained his bachelor’s degree in computer science at University of Southern California.

## Milestones and timelines

Deadlines (Week of)     |Tasks|
------------------------|------------------|
11/16~11/21 |Team members share research findings.11/23~11/27 |Team members decide approaches and implement code to tests datasets. **Current**11/30~12/03 |Testing phases
**12/04** |**Demo**